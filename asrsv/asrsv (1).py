# -*- coding: utf-8 -*-
"""asrsv

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UIuFrFByGGFH8iQSlOreuvm7PmMi0bfH
"""

# ===== 1) CONFIG & BASICS =====
import os, time, json, sqlite3, requests
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime, timezone

# --- Keys (env preferred; fallback to provided) ---
BIRDEYE_API_KEY = os.getenv("BIRDEYE_API_KEY", "7a6cd7e4f6504a6e927b1d0a0a3a9d2d")
HELIUS_API_KEY  = os.getenv("HELIUS_API_KEY",  "03260779-c896-4ebf-8a72-390245121ad8")

# --- Token + reserve wallets ---
ASSET_MINT = os.getenv("ASSET_MINT", "assetSHnT4AzwSGDx6wqv7CWacqjg1LEXnbir3FnSSa")
RESERVE_WALLETS = os.getenv(
    "RESERVE_WALLETS",
    "BtzoeQZAPUr6MLmE947Bxu7PpuJRehaTVadgK2yPVKC6,GyfVNzAvC8FAHRxPtZjm5xhi6mM8PNy2xCe7nNCWnMnk"
).split(",")

# --- Endpoints ---
BIRDEYE_BASE = "https://public-api.birdeye.so"  # Standard plan
HELIUS_RPC   = "https://mainnet.helius-rpc.com"
DB_PATH      = os.getenv("ASSET_DB_PATH", "asset_reserve_metrics.sqlite")

def _be_headers() -> Dict[str, str]:
    if not BIRDEYE_API_KEY:
        raise RuntimeError("Missing BIRDEYE_API_KEY")
    return {"X-API-KEY": BIRDEYE_API_KEY, "x-chain": "solana", "accept": "application/json"}

def http_json(method: str, url: str, headers: Dict[str, str] = None,
              params: Dict[str, Any] = None, json_body: Any = None,
              retries: int = 3, backoff: float = 0.9) -> Any:
    for attempt in range(1, retries + 1):
        r = requests.request(method, url, headers=headers, params=params, json=json_body, timeout=25)
        if r.status_code in (401, 403):
            raise requests.HTTPError(f"{r.status_code} {r.reason} for {url}", response=r)
        if r.status_code == 429:
            time.sleep(backoff * attempt)
            continue
        r.raise_for_status()
        try:
            return r.json()
        except Exception:
            return r.text

def now_utc_iso() -> str:
    return datetime.now(timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ")

# Cheap key sanity check: fail fast if API key is invalid
def birdeye_key_sanity_check() -> None:
    url = f"{BIRDEYE_BASE}/defi/networks"
    _ = http_json("GET", url, headers=_be_headers())

# ===== 2) DB INIT & SCHEMA =====
import sqlite3
from typing import Dict, Any, List, Optional, Tuple

DB_PATH = os.getenv("ASSET_DB_PATH", "asset_reserve_metrics.sqlite")

def with_conn():
    conn = sqlite3.connect(DB_PATH, timeout=30, isolation_level=None)
    cur  = conn.cursor()
    cur.execute("PRAGMA journal_mode=WAL;")
    cur.execute("PRAGMA synchronous=NORMAL;")
    cur.execute("PRAGMA busy_timeout=5000;")
    return conn, cur

def _col_exists(cur, table: str, col: str) -> bool:
    cur.execute(f"PRAGMA table_info({table});")
    return any(row[1] == col for row in cur.fetchall())

def _ensure_column(cur, table: str, col: str, decl: str):
    if not _col_exists(cur, table, col):
        cur.execute(f"ALTER TABLE {table} ADD COLUMN {col} {decl};")

def init_db():
    conn, cur = with_conn()

    # --- Base snapshots (summary) ---
    cur.execute("""
    CREATE TABLE IF NOT EXISTS metrics_snapshots (
      ts_utc TEXT PRIMARY KEY,
      price_usd REAL,
      fdv_usd REAL,
      market_cap_usd REAL,
      circulating_supply REAL,
      real_tvl_total_usd REAL,
      volume_24h_usd REAL,
      collateralization_ratio REAL
    );
    """)

    # --- Per-pool snapshots ---
    cur.execute("""
    CREATE TABLE IF NOT EXISTS pool_snapshots (
      ts_utc TEXT,
      pool_address TEXT,
      family TEXT,
      base_symbol TEXT,
      quote_symbol TEXT,
      liquidity_usd REAL,
      real_tvl_usd REAL,
      volume_24h_usd REAL,
      fee_rate REAL,
      protocol_cut REAL,
      PRIMARY KEY (ts_utc, pool_address)
    );
    """)

    # Backwards/forwards-compat: add columns we now use
    _ensure_column(cur, "pool_snapshots", "source", "TEXT")                       # NEW
    _ensure_column(cur, "pool_snapshots", "gross_fee_24h_usd", "REAL")            # NEW
    _ensure_column(cur, "pool_snapshots", "protocol_fee_24h_usd", "REAL")         # NEW
    _ensure_column(cur, "pool_snapshots", "fee_24h_usd", "REAL")                  # NEW (net LP fee)

    # --- Pools moving 24h pointer for delta calc ---
    cur.execute("""
    CREATE TABLE IF NOT EXISTS pools_state (
      pool_address TEXT PRIMARY KEY,
      last_volume_24h_usd REAL
    );
    """)

    # --- Family totals (all-time) ---
    cur.execute("""
    CREATE TABLE IF NOT EXISTS family_totals (
      family TEXT PRIMARY KEY,
      all_time_volume_usd REAL,
      all_time_fees_usd REAL
    );
    """)

    # --- Per-pool totals (all-time) ---
    cur.execute("""
    CREATE TABLE IF NOT EXISTS pool_totals (
      pool_address TEXT PRIMARY KEY,
      family TEXT,
      all_time_volume_usd REAL,
      all_time_fees_usd REAL
    );
    """)

    # --- Legacy counters (kept for compatibility) ---
    cur.execute("""
    CREATE TABLE IF NOT EXISTS all_time_counters (
      name TEXT PRIMARY KEY,
      value REAL
    );
    """)

    conn.commit()
    conn.close()

def upsert_family_counters(family: str, delta_volume_usd: float, delta_net_fees_usd: float):
    """Increment all-time counters by family."""
    conn, cur = with_conn()
    cur.execute("""
        INSERT INTO family_totals (family, all_time_volume_usd, all_time_fees_usd)
        VALUES (?, ?, ?)
        ON CONFLICT(family) DO UPDATE SET
          all_time_volume_usd = COALESCE(all_time_volume_usd, 0) + excluded.all_time_volume_usd,
          all_time_fees_usd   = COALESCE(all_time_fees_usd, 0)   + excluded.all_time_fees_usd
    """, (family, float(delta_volume_usd or 0.0), float(delta_net_fees_usd or 0.0)))
    conn.commit()
    conn.close()

def get_all_time_counters():
    """Return list of {family, all_time_volume_usd, all_time_fees_usd} for printing."""
    conn, cur = with_conn()
    cur.execute("""
        SELECT family, COALESCE(all_time_volume_usd,0), COALESCE(all_time_fees_usd,0)
        FROM family_totals
        ORDER BY all_time_volume_usd DESC
    """)
    rows = [{"family": r[0], "all_time_volume_usd": r[1], "all_time_fees_usd": r[2]} for r in cur.fetchall()]
    conn.close()
    return rows

init_db()

# ===== 3) BIRDEYE HELPERS (standard plan) =====
import requests, time

BIRDEYE_BASE = "https://public-api.birdeye.so"

def _be_headers():
    return {
        "accept": "application/json",
        "x-chain": "solana",
        "X-API-KEY": BIRDEYE_API_KEY,   # from Cell 1
    }

def _http_json(method, url, *, headers=None, params=None, json_body=None, retries=3, backoff=0.9):
    for attempt in range(1, retries+1):
        r = requests.request(method, url, headers=headers, params=params, json=json_body, timeout=25)
        if r.status_code == 429 and attempt < retries:
            time.sleep(backoff * attempt)
            continue
        r.raise_for_status()
        return r.json()

def birdeye_key_probe():
    _http_json("GET", f"{BIRDEYE_BASE}/defi/networks", headers=_be_headers())

def be_markets_v2(token_addr: str, *, sort_by="liquidity", limit=50, time_frame="24h"):
    """Return list of market objects for the token from /defi/v2/markets."""
    url = f"{BIRDEYE_BASE}/defi/v2/markets"
    items, offset = [], 0
    while len(items) < limit:
        params = {
            "address": token_addr,
            "time_frame": time_frame,
            "sort_type": "desc",
            "sort_by": sort_by,
            "offset": offset,
            "limit": min(20, limit - len(items)),
        }
        j = _http_json("GET", url, headers=_be_headers(), params=params)
        page = (j or {}).get("data", {}).get("items", []) or []
        items.extend(page)
        if not page:
            break
        offset += len(page)
    return items

def be_price(token_addr: str) -> float:
    """Spot price (USD) from /defi/price (BirdEye Standard plan supports it)."""
    j = _http_json(
        "GET",
        f"{BIRDEYE_BASE}/defi/price",
        headers=_be_headers(),
        params={"address": token_addr, "include_liquidity": "true"},
    )
    data = j.get("data", j) or {}
    try:
        return float(data.get("value") or 0.0)
    except Exception:
        return 0.0

# quick fail-fast check
birdeye_key_probe()


# ---------- Helius RPC: total supply + per-owner balances ----------
def helius_rpc(method: str, params: Any) -> Any:
    url = f"{HELIUS_RPC}/?api-key={HELIUS_API_KEY}"
    body = {"jsonrpc": "2.0", "id": method, "method": method, "params": params}
    return http_json("POST", url, headers={"accept":"application/json","content-type":"application/json"}, json_body=body)

def helius_get_token_supply(mint: str) -> float:
    j = helius_rpc("getTokenSupply", [mint])
    try:
        val = j["result"]["value"]
        if val.get("uiAmount") is not None:
            return float(val["uiAmount"])
        return float(val["amount"]) / (10 ** int(val["decimals"]))
    except Exception:
        return 0.0

def helius_get_owner_token_balance(owner: str, mint: str) -> float:
    j = helius_rpc("getTokenAccountsByOwner", [owner, {"mint": mint}, {"encoding": "jsonParsed"}])
    total = 0.0
    try:
        for acc in j.get("result", {}).get("value", []):
            info = acc.get("account", {}).get("data", {}).get("parsed", {}).get("info", {})
            amt  = info.get("tokenAmount", {})
            if amt.get("uiAmount") is not None:
                total += float(amt["uiAmount"])
            else:
                total += float(amt.get("amount", 0)) / (10 ** int(amt.get("decimals", 0)))
    except Exception:
        pass
    return total

def helius_get_reserve_total(mint: str, reserve_wallets: List[str]) -> float:
    s = 0.0
    for w in reserve_wallets:
        s += helius_get_owner_token_balance(w.strip(), mint)
    return s

# ---------- Meteora DAMM v2: per-pool fee rate & protocol cut ----------
METEORA_DETAIL_BASE = "https://dammv2-api.meteora.ag"
_METEORA_POOL_CACHE: Dict[str, Dict[str, Any]] = {}
_METEORA_METRICS_CACHE: Dict[str, Dict[str, Any]] = {}

def meteora_get_pool(pool_address: str) -> Dict[str, Any]:
    pool_address = pool_address.strip()
    if pool_address in _METEORA_POOL_CACHE:
        return _METEORA_POOL_CACHE[pool_address]
    url = f"{METEORA_DETAIL_BASE}/pools/{pool_address}"
    j = http_json("GET", url)
    data = j.get("data", j)
    _METEORA_POOL_CACHE[pool_address] = data
    return data

def _as_fraction_from_pct(x: Optional[float]) -> float:
    try:
        v = float(x)
    except:
        return 0.0
    return v / 100.0  # your pools give fees in %, so divide by 100

def meteora_fee_and_protocol_cut(pool_address: str) -> Tuple[float, float]:
    """
    fee_rate = (base_fee + dynamic_fee) / 100
    protocol_cut = fixed 20%
    """
    try:
        p = meteora_get_pool(pool_address)
        base_fee = _as_fraction_from_pct(p.get("base_fee") or 0.0)
        dyn_fee  = _as_fraction_from_pct(p.get("dynamic_fee") or 0.0)
        fee_rate = max(base_fee + dyn_fee, 0.0)
        return fee_rate, 0.20
    except Exception:
        return 0.003, 0.20

# ===== 4) PRICE, SUPPLIES, CIRCULATING & NORMALIZATION =====

def get_price_usd() -> float:
    return float(be_price(ASSET_MINT) or 0.0)

def get_total_supply() -> float:
    return helius_get_token_supply(ASSET_MINT)

def get_circulating_supply(total_supply: float) -> float:
    reserve_total = helius_get_reserve_total(ASSET_MINT, RESERVE_WALLETS)
    return max(total_supply - reserve_total, 0.0)

def normalize_pool_row(p: Dict[str, Any]) -> Dict[str, Any]:
    base = (p.get("base")  or {}) ; quote = (p.get("quote") or {})
    return {
        "address":   str(p.get("address")),
        "family":    str(p.get("source") or p.get("dex") or "Unknown"),
        "base_sym":  str(base.get("symbol")  or ""),
        "quote_sym": str(quote.get("symbol") or ""),
        "liquidity": float(p.get("liquidity") or 0.0),
        "volume24h": float(p.get("volume24h") or 0.0),
    }

# ===== 5) SNAPSHOT + ACCUMULATE (BirdEye + fixed fees + APY) =====
import sqlite3, math, datetime, requests
from collections import defaultdict

# --- protocol cuts (configurable) ---
PROTOCOL_CUTS = {"meteora": 0.20, "raydium": 0.16, "orca": 0.20}

def _protocol_cut(source: str) -> float:
    s = (source or "").lower()
    if "meteora" in s: return PROTOCOL_CUTS["meteora"]
    if "raydium" in s: return PROTOCOL_CUTS["raydium"]
    if "orca"    in s: return PROTOCOL_CUTS["orca"]
    return 0.0

# --- Your intended fee policy (override any API noise) ---
# default 1% (0.01), but asset-USDC pools are 0.25% (0.0025)
DEFAULT_FEE_RATE = 0.01
USDC_FEE_RATE    = 0.0025

def fee_rate_for_pair(family: str, quote_symbol: str) -> float:
    fam = (family or "").lower()
    qs  = (quote_symbol or "").upper()
    if "usdc" in fam or qs == "USDC":
        return USDC_FEE_RATE
    return DEFAULT_FEE_RATE

def _ensure_aux_tables():
    conn, cur = with_conn()
    cur.execute("""
    CREATE TABLE IF NOT EXISTS pools_state (
      pool_address TEXT PRIMARY KEY,
      last_volume_24h_usd REAL
    )""")
    conn.commit()
    conn.close()

def price_fdv_mc():
    price = be_price(ASSET_MINT)
    total_supply = helius_get_token_supply(ASSET_MINT)
    circulating  = max(total_supply - helius_get_reserve_total(ASSET_MINT, RESERVE_WALLETS), 0.0)
    fdv = price * total_supply
    mc  = price * circulating
    return price, fdv, mc, total_supply, circulating

def snapshot_and_accumulate():
    _ensure_aux_tables()

    # 1) Price / supply
    price, fdv, mc, total_supply, circulating = price_fdv_mc()

    # 2) Markets from BirdEye
    items = be_markets_v2(ASSET_MINT, sort_by="liquidity", limit=50, time_frame="24h")

    rows = []
    exposures_usd = defaultdict(float)
    exposures_units = defaultdict(float)

    total_real_tvl = 0.0
    total_vol_24h  = 0.0
    total_fees_24h = 0.0

    for it in items:
        pool_addr = it.get("address")
        base_sym  = (it.get("base")  or {}).get("symbol", "") or ""
        quote_sym = (it.get("quote") or {}).get("symbol", "") or ""
        liq_usd   = float(it.get("liquidity") or 0.0)
        vol_24h   = float(it.get("volume24h") or 0.0)
        family    = it.get("name") or ""                 # e.g., "asset-USDC"
        source    = it.get("source") or ""               # e.g., "Meteora Damm V2"

        real_tvl_usd = liq_usd / 2.0
        protocol_cut = _protocol_cut(source)

        # --- Use your fixed fee schedule ---
        fee_rate = fee_rate_for_pair(family, quote_sym)

        # --- We don't rely on Meteora dynamic fees here; only need units for exposures if desired ---
        quote_units = 0.0  # leave 0 unless you separately fetch pool reserves

        # --- Fees and yields ---
        gross_fees_24h     = vol_24h * fee_rate
        protocol_fees_24h  = gross_fees_24h * protocol_cut
        net_fees_24h       = gross_fees_24h - protocol_fees_24h

        daily_yield = (net_fees_24h / real_tvl_usd) if real_tvl_usd > 0 else 0.0
        # guard against silly API spikes: compute but mark if absurd
        flagged_unrealistic = daily_yield > 1.0  # >100% in a single day
        apy_simple  = daily_yield * 365.0
        apy_comp    = (math.pow(1.0 + daily_yield, 365.0) - 1.0) if daily_yield > 0 else 0.0

        rows.append({
            "pool_address": pool_addr,
            "family": family,
            "source": "Meteora" if "meteora" in (source or "").lower() else (source or "Unknown"),
            "base_symbol": base_sym,
            "quote_symbol": (quote_sym or "UNKNOWN").strip(),
            "liquidity_usd": liq_usd,
            "real_tvl_usd": real_tvl_usd,
            "volume_24h_usd": vol_24h,
            "fee_rate": fee_rate,
            "protocol_cut": protocol_cut,
            "gross_fee_24h_usd": gross_fees_24h,
            "protocol_fee_24h_usd": protocol_fees_24h,
            "fee_24h_usd": net_fees_24h,
            "daily_yield": daily_yield,
            "apy_simple": apy_simple,
            "apy_compound": apy_comp,
            "quote_amount": quote_units,
            "flagged_unrealistic": flagged_unrealistic,
        })

        exposures_usd[quote_sym or "UNKNOWN"]   += real_tvl_usd
        exposures_units[quote_sym or "UNKNOWN"] += quote_units

        total_real_tvl += real_tvl_usd
        total_vol_24h  += vol_24h
        total_fees_24h += net_fees_24h

    # 3) Persist snapshot + all-time counters
    ts = datetime.datetime.now(datetime.timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ")
    conn, cur = with_conn()

    for r in rows:
        cur.execute("""
            INSERT INTO pool_snapshots
            (ts_utc, pool_address, family, base_symbol, quote_symbol,
             liquidity_usd, real_tvl_usd, volume_24h_usd, fee_rate, protocol_cut, source,
             gross_fee_24h_usd, protocol_fee_24h_usd, fee_24h_usd)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            ts, r["pool_address"], r["family"], r["base_symbol"], r["quote_symbol"],
            r["liquidity_usd"], r["real_tvl_usd"], r["volume_24h_usd"], r["fee_rate"], r["protocol_cut"], r["source"],
            r["gross_fee_24h_usd"], r["protocol_fee_24h_usd"], r["fee_24h_usd"]
        ))

        # 24h volume delta per pool
        cur.execute("SELECT last_volume_24h_usd FROM pools_state WHERE pool_address = ?", (r["pool_address"],))
        prev = cur.fetchone()
        last = float(prev[0]) if prev and prev[0] is not None else 0.0
        delta_vol = max(0.0, r["volume_24h_usd"] - last)

        gross_delta = delta_vol * r["fee_rate"]
        net_delta   = gross_delta * (1.0 - r["protocol_cut"])
        upsert_family_counters(r["family"], delta_vol, net_delta)

        cur.execute("""
            INSERT INTO pools_state (pool_address, last_volume_24h_usd)
            VALUES (?, ?)
            ON CONFLICT(pool_address) DO UPDATE SET last_volume_24h_usd = excluded.last_volume_24h_usd
        """, (r["pool_address"], r["volume_24h_usd"]))

    cur.execute("""
        INSERT OR REPLACE INTO metrics_snapshots
        (ts_utc, price_usd, fdv_usd, market_cap_usd, circulating_supply,
         real_tvl_total_usd, volume_24h_usd, collateralization_ratio)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?)
    """, (
        ts, price, fdv, mc, circulating,
        total_real_tvl, total_vol_24h,
        (total_real_tvl / fdv) if fdv > 0 else 0.0,
    ))

    conn.commit()
    conn.close()

    # 4) Read back family totals for printout
    fam_rows = get_all_time_counters()

    # exposures (sorted)
    exp_total = total_real_tvl or 1.0
    exposures_list = [
        {"quote_symbol": sym, "real_tvl": amt, "weight": amt/exp_total}
        for sym, amt in sorted(exposures_usd.items(), key=lambda kv: kv[1], reverse=True)
    ]
    exposures_units_list = [
        {"quote_symbol": sym, "units": units}
        for sym, units in sorted(exposures_units.items(), key=lambda kv: kv[1], reverse=True)
    ]

    portfolio_daily_yield = (total_fees_24h / total_real_tvl) if total_real_tvl > 0 else 0.0
    portfolio_apy_simple  = portfolio_daily_yield * 365.0
    portfolio_apy_comp    = (math.pow(1.0 + portfolio_daily_yield, 365.0) - 1.0) if portfolio_daily_yield > 0 else 0.0

    return {
        "ts_utc": ts,
        "pools_count": len(rows),

        "price_usd": price,
        "fdv_usd": fdv,
        "market_cap_usd": mc,
        "circulating_supply": circulating,

        "real_tvl_total_usd": total_real_tvl,
        "volume_24h_total_usd": total_vol_24h,
        "fees24h_total_usd_est": total_fees_24h,

        "real_yield_daily": portfolio_daily_yield,
        "apy_simple": portfolio_apy_simple,
        "apy_compound": portfolio_apy_comp,

        "collateralization_ratio": (total_real_tvl / fdv) if fdv > 0 else 0.0,

        "exposures": exposures_list,
        "exposures_units": exposures_units_list,

        "families": fam_rows,
        "per_pool": rows,
    }

# ===== 6) RUN ONCE =====
def print_dashboard(d):
    print(json.dumps({
        "ts": d["ts_utc"],
        "price_usd": round(d["price_usd"], 8),
        "fdv_usd": round(d["fdv_usd"], 2),
        "market_cap_usd": round(d["market_cap_usd"], 2),
        "circulating_supply": round(d["circulating_supply"], 4),
        "real_tvl_total_usd": round(d["real_tvl_total_usd"], 2),
        "volume_24h_total_usd": round(d["volume_24h_total_usd"], 2),
        "fees24h_total_usd_est": round(d["fees24h_total_usd_est"], 4),
        "collateralization_ratio": round(d["collateralization_ratio"], 6),
        "apy_simple": round(d["apy_simple"], 6),
        "apy_compound": round(d["apy_compound"], 6),
        "exposures": d["exposures"],
        "families": d["families"],
        "pools_count": d["pools_count"],
    }, indent=2))

dash = snapshot_and_accumulate()
print_dashboard(dash)

# Optional: quick per-pool view with APY & units
for p in dash["per_pool"]:
    print({
        "family": p["family"],
        "source": p["source"],
        "fee_rate": p["fee_rate"],
        "protocol_cut": p["protocol_cut"],
        "volume_24h_usd": round(p["volume_24h_usd"], 4),
        "real_tvl_usd": round(p["real_tvl_usd"], 2),
        "fee24h_est": round(p["fee_24h_usd"], 4),
        "daily_yield_pct": f"{p['daily_yield']*100:.3f}%",
        "apy_simple_pct":  f"{p['apy_simple']*100:.2f}%",
        "apy_comp_pct":    f"{p['apy_compound']*100:.2f}%",
        "quote_symbol": p["quote_symbol"],
        "quote_amount": p["quote_amount"],  # units
    })